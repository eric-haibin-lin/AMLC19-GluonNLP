{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deployment with TVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Pre-trained language representations have been shown to improve many downstream NLP tasks such as question answering, and natural language inference. Devlin, Jacob, et al proposed BERT [1] (Bidirectional Encoder Representations from Transformers), which fine-tunes deep bidirectional representations on a wide range of tasks with minimal task-specific parameters, and obtained state- of-the-art results.\n",
    "\n",
    "In this tutorial, we will focus on adapting the BERT model for the question answering task on the SQuAD dataset. Specifically, we will:\n",
    "\n",
    "- understand how to pre-process the SQuAD dataset to leverage the learnt representation in BERT,\n",
    "- adapt the BERT model to the question answering task, and\n",
    "- load a trained model to perform inference on the SQuAD dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Load MXNet, GluonNLP, and TVM\n",
    "\n",
    "We first import the libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.416134Z",
     "start_time": "2019-06-14T01:45:26.339759Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections, time, logging\n",
    "import numpy as np\n",
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "import bert\n",
    "import qa_utils\n",
    "from bert.bert_qa_evaluate import PredResult, predict\n",
    "from bert.export.hybrid_bert import HybridBERTForQA, get_hybrid_model\n",
    "from bert.data.qa import SQuADTransform, preprocess_dataset\n",
    "# TVM libraries\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm import autotvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load hybrid BERT model\n",
    "\n",
    "Currently hybrid BERT model for QA doesn't support control flow, we need to specify a maximum sequence length and padded the input to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.715444Z",
     "start_time": "2019-06-14T01:45:27.569118Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded checkpoint to ./temp/bert_qa-7eb11865.params\n"
     ]
    }
   ],
   "source": [
    "from bert.export.hybrid_bert import HybridBERTForQA, get_hybrid_model\n",
    "max_seq_length = 256\n",
    "max_query_length = 64\n",
    "base_model, vocab = get_hybrid_model(\n",
    "    name=\"bert_12_768_12\",\n",
    "    dataset_name=\"book_corpus_wiki_en_uncased\",\n",
    "    pretrained=False,\n",
    "    use_pooler=False,\n",
    "    use_decoder=False,\n",
    "    use_classifier=False,\n",
    "    seq_length=max_seq_length)\n",
    "\n",
    "net = HybridBERTForQA(base_model)\n",
    "mx_ctx = mx.cpu()\n",
    "ckpt = qa_utils.download_qa_ckpt()\n",
    "net.load_parameters(ckpt, ctx=mx_ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T01:45:27.555133Z",
     "start_time": "2019-06-14T01:45:27.418706Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Transform dataset costs 0.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "full_data = nlp.data.SQuAD(segment='dev', version='1.1')\n",
    "# loading a subset of the dev set of SQuAD\n",
    "num_target_samples = 20\n",
    "target_samples = [full_data[i] for i in range(num_target_samples)]\n",
    "dataset = mx.gluon.data.SimpleDataset(target_samples)\n",
    "#print('Number of samples in the created dataset subsampled from SQuAD = %d'%len(dataset))\n",
    "\n",
    "tokenizer = nlp.data.BERTTokenizer(vocab=vocab, lower=True)\n",
    "transform = bert.data.qa.SQuADTransform(tokenizer, is_pad=False, is_training=False, do_lookup=False)\n",
    "dev_data_transform, _ = bert.data.qa.preprocess_dataset(dataset, transform)\n",
    "#print('The number of examples after preprocessing:{}'.format(len(dev_data_transform)))\n",
    "\n",
    "def vocab_lookup(example_id, subwords, type_ids, length, start, end):\n",
    "    indices = vocab[subwords]\n",
    "    return example_id, indices, type_ids, length, start, end\n",
    "dev_data_transform = dev_data_transform.transform(vocab_lookup, lazy=False)\n",
    "\n",
    "batch_size = 1\n",
    "dev_dataloader = mx.gluon.data.DataLoader(\n",
    "    dev_data_transform, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile MXNet model with TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the MXNet model into Relay. We need to provide a mapping from input names to their shapes for conversion. TVM frontend converter supports both MXNet static graph (symbol) and HybridBlock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_dict = {\n",
    "    'data0': (1, max_seq_length), # inputs\n",
    "    'data1': (1, max_seq_length), # token types\n",
    "    'data2': (1,) # sequence length\n",
    "}\n",
    "mod, params = relay.frontend.from_mxnet(net, shape_dict)\n",
    "# uncomment the following line to see the converted model in Relay IR\n",
    "# print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the AutoTVM logs and build module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the AutoTVM search logs that were previously generated when tuning on c5.9x instances. These logs contain thousands of tuning results and then apply the best schedule during compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"autotvm_logs\"\n",
    "logs = [os.path.join(log_dir, f) for f in os.listdir(log_dir)]\n",
    "autotvm_ctx = autotvm.apply_history_best(None)\n",
    "for log_file in logs:\n",
    "    autotvm_ctx.load(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile the model. We specify the target CPU as skylake avx512 in order to use the vectorized instructions for floating operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"llvm -mcpu=skylake-avx512\"\n",
    "# change the target when compile on ARM CPU\n",
    "# target = \"llvm -device=arm_cpu -target=aarch64-linux-gnu\"\n",
    "with autotvm_ctx:\n",
    "    with relay.build_config(opt_level=3):\n",
    "        graph, lib, params = relay.build(mod[mod.entry_func], target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate TVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the graph runtime to execute the compiled graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.contrib.graph_runtime as runtime\n",
    "\n",
    "tvm_ctx = tvm.cpu()\n",
    "ex = runtime.create(graph, lib, tvm_ctx)\n",
    "ex.set_input(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost=2.39 s, Thoughput=8.36 samples/s\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question: which nfl team represented the afc at super bowl 50 ?\n",
      "\n",
      "Top predictions: \n",
      "99.36% \t Denver Broncos\n",
      "0.23% \t The American Football Conference (AFC) champion Denver Broncos\n",
      "0.20% \t Broncos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def pad(arr, length, pad_val, dtype=\"float32\"):\n",
    "    padded = np.full(shape=(1, length), fill_value=pad_val, dtype=dtype)\n",
    "    padded[0, :arr.shape[1]] = arr.asnumpy()[0]\n",
    "    return padded\n",
    "\n",
    "tvm_results = collections.defaultdict(list)\n",
    "epoch_tic = time.time()\n",
    "total_num = 0\n",
    "for data in dev_dataloader:\n",
    "    example_ids, inputs, token_types, valid_length, _, _ = data\n",
    "    total_num += len(inputs)\n",
    "    padded_inputs = pad(inputs, max_seq_length, vocab[vocab.padding_token])\n",
    "    padded_token_types = pad(token_types, max_seq_length, 0)\n",
    "    ex.set_input(data0=padded_inputs,\n",
    "                 data1=padded_token_types,\n",
    "                 data2=valid_length.astype('float32').asnumpy())\n",
    "    ex.run()\n",
    "    out = ex.get_output(0)\n",
    "    output = np.split(out.asnumpy(), axis=2, indices_or_sections=2)\n",
    "    example_ids = example_ids.asnumpy().tolist()\n",
    "    pred_start = output[0].reshape((1, -1))\n",
    "    pred_end = output[1].reshape((1, -1))\n",
    "\n",
    "    for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "        tvm_results[example_id].append(PredResult(start=start, end=end))\n",
    "\n",
    "epoch_toc = time.time()\n",
    "print('Time cost={:.2f} s, Thoughput={:.2f} samples/s'.format(\n",
    "    epoch_toc - epoch_tic, total_num/(epoch_toc - epoch_tic)))\n",
    "\n",
    "qa_utils.predict(dataset, tvm_results, vocab, number=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost=1.77 s, Thoughput=11.28 samples/s\n",
      "\n",
      "Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.\n",
      "\n",
      "Question: which nfl team represented the afc at super bowl 50 ?\n",
      "\n",
      "Top predictions: \n",
      "99.36% \t Denver Broncos\n",
      "0.23% \t The American Football Conference (AFC) champion Denver Broncos\n",
      "0.20% \t Broncos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mx_results = collections.defaultdict(list)\n",
    "\n",
    "epoch_tic = time.time()\n",
    "total_num = 0\n",
    "for data in dev_dataloader:\n",
    "    example_ids, inputs, token_types, valid_length, _, _ = data\n",
    "    total_num += len(inputs)\n",
    "    padded_inputs = pad(inputs, max_seq_length, vocab[vocab.padding_token])\n",
    "    padded_token_types = pad(token_types, max_seq_length, 0)\n",
    "    out = net(mx.nd.array(padded_inputs, mx_ctx),\n",
    "              mx.nd.array(padded_token_types, mx_ctx),\n",
    "              valid_length.astype('float32').as_in_context(mx_ctx))\n",
    "\n",
    "    output = mx.nd.split(out, axis=2, num_outputs=2)\n",
    "    example_ids = example_ids.asnumpy().tolist()\n",
    "    pred_start = output[0].reshape((0, -3)).asnumpy()\n",
    "    pred_end = output[1].reshape((0, -3)).asnumpy()\n",
    "\n",
    "    for example_id, start, end in zip(example_ids, pred_start, pred_end):\n",
    "        mx_results[example_id].append(PredResult(start=start, end=end))\n",
    "\n",
    "epoch_toc = time.time()\n",
    "print('Time cost={:.2f} s, Thoughput={:.2f} samples/s'.format(\n",
    "    epoch_toc - epoch_tic, total_num/(epoch_toc - epoch_tic)))\n",
    "\n",
    "qa_utils.predict(dataset, mx_results, vocab, number=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark TVM performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TVM mean inference time: 102.72 ms\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.uniform(size=(1, max_seq_length)).astype('float32')\n",
    "token_types = np.random.uniform(size=(1, max_seq_length)).astype('float32')\n",
    "valid_length = np.asarray([max_seq_length]).astype('float32')\n",
    "\n",
    "ftimer = ex.module.time_evaluator(\"run\", tvm_ctx, number=20, min_repeat_ms=1000)\n",
    "prof_res = np.array(ftimer().results) * 1000  # convert to millisecond\n",
    "print(\"TVM mean inference time: %.2f ms\" % np.mean(prof_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MXNet mean inference time: 85.93 ms\n"
     ]
    }
   ],
   "source": [
    "inputs_nd = mx.nd.array(inputs)\n",
    "token_types_nd = mx.nd.array(token_types)\n",
    "valid_length_nd = mx.nd.array(valid_length)\n",
    "mx_out = net(inputs_nd, token_types_nd, valid_length_nd)\n",
    "mx_out.wait_to_read()\n",
    "\n",
    "min_repeat_ms = 1000\n",
    "number = 20\n",
    "while True:\n",
    "    beg = time.time()\n",
    "    for _ in range(number):\n",
    "        mx_out = net(inputs_nd, token_types_nd, valid_length_nd)\n",
    "        mx_out.wait_to_read()\n",
    "    end = time.time()\n",
    "    lat = (end - beg) * 1e3\n",
    "    if lat >= min_repeat_ms:\n",
    "        break\n",
    "    number = int(max(min_repeat_ms / (lat / number) + 1, number * 1.618))\n",
    "print('MXNet mean inference time: %.2f ms' % (lat / number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
